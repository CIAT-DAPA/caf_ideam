cor_raster=ras[[1]]
values(cor_raster)=cor
q1=quantile(cor,as.numeric(dec),na.rm=T)
jBrewColors <- brewer.pal(n = 9, name = "Reds")
tiff(paste0(all_name,".tiff"),compression = 'lzw',height = 6.5,width = 5.7,units="in", res=150)
par(mfrow=c(2,1))
plot(cor_raster,main="Weighted loadings",col=jBrewColors,colNA="gray",legend.width=1,legend.shrink=1)
plot(cor_raster>= q1,main="Selected pixels",colNA="gray",legend=F,col=jBrewColors)
dev.off()
return(print("Área seleccionada guardada en formato Raster"))
}
eigen_plot <- function(path_raw, path_output){
xeigen<- read.csv(paste0(path_raw, "_pca_eigen_x.txt"),skip =2, header=T, sep="")
yeigen <- read.csv(paste0(path_raw,"_pca_eigen_y.txt"),skip =2, header=T, sep="")
datos_e <- data.frame(modes=xeigen$Mode, eigenx=xeigen$variance, eigeny=yeigen$variance, row.names = NULL)
# grÃ¡fico de los modos
modosx <-  ggplot(datos_e, aes(modes,group = 1)) +   geom_line(aes(y = eigenx ),  colour="firebrick3" ) + geom_point(aes(y = eigenx ),  colour="firebrick3" ) +
theme_bw() + theme( title =element_text(size=12, face='bold'),axis.text.y = element_text(size=12),  legend.position = "none", axis.text.x = element_text(angle = 0, hjust = 1, size = 12)) +
guides(colour = guide_legend(title = " ")) + labs(x="Mode",y="% variance",title = "X Scree Plot")
modosy <-  ggplot(datos_e, aes(modes,group = 1)) +   geom_line(aes(y = eigeny ),  colour="firebrick3" ) + geom_point(aes(y = eigeny ),  colour="firebrick3" ) +
theme_bw() + theme( title =element_text(size=12, face='bold'),axis.text.y = element_text(size=12),  legend.position = "none", axis.text.x = element_text(angle = 0, hjust = 1, size = 12)) +
guides(colour = guide_legend(title = " ")) + labs(x="Mode",y="% variance",title = "Y Scree Plot")
layt<-grid.layout(nrow=1,ncol=2)
trim_n = unlist(strsplit(path_raw,"/"))
trim_n = trim_n[length(trim_n)]
tiff(filename = paste0(path_output,"/",trim_n, "_eigen_plot.tif"), width = 1500, height = 800,res=150,compression = 'lzw')
grid.newpage()
pushViewport(viewport(layout=layt))
print(modosx,vp=viewport(layout.pos.row=1,layout.pos.col=1))
print(modosy,vp=viewport(layout.pos.row=1,layout.pos.col=2))
dev.off()
cat(paste0(trim_n)," Scree plots realizados...\n")
}
cca_map <- function(path_raw , path_output,i, coor) {
xserie <- read.csv(paste0(path_raw, "_cca_scores_x.txt"),skip =2, header=T, sep="")
yserie <- read.csv(paste0(path_raw,"_cca_scores_y.txt"),skip =2, header=T, sep="")
yloadcca <-  read.csv(paste0(path_raw, "_cca_load_y.txt"),skip =2, header=T, sep="")
yloadcca[yloadcca==-999.99000000] <-NA
yloadcca <- na.omit(yloadcca)
## =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= ##
## CCA Maps
## =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= ##
x = tables[[i]]
ext = c(min(as.numeric(coor[[2]])),max(as.numeric(coor[[2]])),min(as.numeric(coor[[1]])),max(as.numeric(coor[[1]])))
mapa_base=raster(nrow=dim(x)[1],ncol=dim(x)[2])
extent(mapa_base) <- extent(ext[3],ext[4],ext[1],ext[2])
val=c(as.matrix(t(x),ncol=1,byrow = T))
val=as.numeric(val)
val[val==-999.000]=NA
val = val/max(abs(val),na.rm=T)
values(mapa_base)=val
#myPalette <-  colorRampPalette(c("navyblue","#2166AC", "dodgerblue3","lightblue", "lightcyan",  "white",  "yellow","orange", "orangered","#B2182B", "red4"))
myPalette <-  colorRampPalette(c("dodgerblue4", "dodgerblue1","deepskyblue","darkslategray1", "lightcyan",  "white",  "lemonchiffon1","khaki","sandybrown", "darkorange2","firebrick2"))
Map_x<- rasterVis::gplot(mapa_base) + geom_tile(aes(fill = value)) + coord_equal() +
labs(title=paste0("X Spatial Loadings (Mode ",i,")"),x="",y=" ", fill = " ")  + theme(legend.key.height=unit(0.5,"cm"),legend.key.width=unit(2,"cm"),
legend.text=element_text(size=10),
panel.background=element_rect(fill="white",colour="black"),
axis.text=element_text(colour="black",size=12),
axis.title=element_text(colour="black",size=12,face="bold"),
legend.position = "bottom",
legend.title = element_text(size = 12.5))  +
scale_fill_gradientn(colours =myPalette(100), limits=c(-1,1))
yloadcca$val = yloadcca[,i+3]/max(abs(yloadcca[,i+3]),na.rm=T)
y = yloadcca
ext_y = c(min(as.numeric(y$Latitude))-0.5,max(as.numeric(y$Latitude))+0.5,min(as.numeric(y$Longitude))-0.5,max(as.numeric(y$Longitude))+0.5)
sPDF <<- getMap()
new_map = fortify(sPDF)
sel <<-new_map[new_map$lat>ext_y[1] & new_map$lat<ext_y[2] & new_map$long>ext_y[3] & new_map$long<ext_y[4],]
p <- ggplot(sel, aes(x=long,y=lat))
p <- p + geom_polygon(aes(fill=hole,group=group),fill="snow") +
scale_fill_manual(values=c("grey 80","grey 80"))
p <- p + geom_point(data=y, aes(x=Longitude, y=Latitude, col=val),size=1)
p <- p + scale_color_gradientn(colours =myPalette(100), limits=c(-1,1)) + coord_equal()+ geom_path(aes(long,lat,group=group),color="black",size=0.3)
p <-  p + theme(legend.key.height=unit(1,"cm"),legend.key.width=unit(0.5,"cm"),
legend.text=element_text(size=12),
panel.background=element_rect(fill="white",colour="black"),
axis.text=element_text(colour="black",size=12),
axis.title=element_text(colour="black",size=12,face="bold"),
#legend.position = "bottom",
legend.title = element_text(size = 12)) + labs(title=paste0("Y Spatial Loadings (Mode ",i,")"),  x= "", y= "", colour="")
## GrÃ¡ficos Componentes
# Se crea una trama de datos con la fecha y las componentes
datos <- data.frame(X=xserie[,i], Y=yserie[,i], row.names = NULL)
datos$X = round(datos$X ,4) # redondee los modos
datos$Y = round(datos$Y ,4) # redondee los modos
datos$date = as.numeric(substring(rownames(xserie),1,4))
datos[datos$X==-999.0000,1:2]=0
datos[datos$Y==-999.0000,1:2]=0 # quite los valore NA
# quite los valore NA
datos[,1:2]=datos[,1:2]*100 # multipliquelos * 100
modos <-  ggplot(datos, aes(date,group = 1)) +   geom_line(aes(y = X ),  colour="firebrick3" ) +
geom_line(aes(y = Y),  colour="forestgreen")  +
geom_hline(yintercept = 0, colour="gray") + theme_bw() +
theme( title =element_text(size=12, face='bold'),axis.text.y = element_text(size=12),  legend.position = "none", axis.text.x = element_text(angle = 90, hjust = 1, size = 12)) +
guides(colour = guide_legend(title = " ")) + labs(subtitle=paste("Canonical Correlation = ", round(cor(datos$X,datos$Y),3),sep = ""),x="",y="Scores (X red; Y green) (*100)",
title = paste0("Temporal Scores (Mode " ,i,")")) + scale_x_continuous(breaks = seq(min(datos$date),max(datos$date),3))
layt<-grid.layout(nrow=1,ncol=3,widths=c(4/9,2.5/9, 2.5/9),default.units=c('null','null'))
trim_n = unlist(strsplit(path_raw,"/"))
trim_n = trim_n[length(trim_n)]
tiff(filename = paste0(path_output, "/",trim_n,"_mode_",i,"_cca_maps.tif"), width = 1700, height = 400,res=100,compression = 'lzw')
grid.newpage()
pushViewport(viewport(layout=layt))
print(Map_x,vp=viewport(layout.pos.row=1,layout.pos.col=1))
print(modos,vp=viewport(layout.pos.row=1,layout.pos.col=2))
print(p,vp=viewport(layout.pos.row=1,layout.pos.col=3))
dev.off()
cat(paste0(trim_n), " Mapas CCA realizados...\n")
}
cca_map_all <- function(path_raw,path_output){
y <- read.table(paste0(path_raw, "_cca_load_x.txt"),sep="\t",dec=".",skip =2,fill=TRUE,na.strings =-999,stringsAsFactors=FALSE)
y[1,1]=""
loadings <- na.omit(y)
loadings[loadings==-999]=NA
pos=which(loadings[,1]=="")
if(length(pos)==1){list_dates=list(loadings)}else{vector_split <- sort(rep(pos,pos[2]-1));list_dates <- split(loadings,vector_split)}
coor <- list(list_dates[[1]][1,][-1],list_dates[[1]][,1][-1])
tables <<- lapply(list_dates,"[",-1,-1)
for(i in 1:length(tables)) cca_map(path_raw,path_output,i,coor)
}
metric_map <- function(path_metric, path_output,path_raw){
yloadcca <-  read.csv(paste0(path_raw, "_cca_load_y.txt"),skip =2, header=T, sep="")
y = yloadcca
ext_y = c(min(as.numeric(y$Latitude))-0.5,max(as.numeric(y$Latitude))+0.5,min(as.numeric(y$Longitude))-0.5,max(as.numeric(y$Longitude))+0.5)
sPDF <<- getMap()
new_map = fortify(sPDF)
sel <<-new_map[new_map$lat>ext_y[1] & new_map$lat<ext_y[2] & new_map$long>ext_y[3] & new_map$long<ext_y[4],]
all_ind_complete_na <-read.csv(paste0(path_metric, '/metrics.csv'), na.strings = c(-999.99, -1))
all_ind_complete <-na.omit(all_ind_complete_na)
trimesters <- unique(all_ind_complete$file)
for(i in 1:length(trimesters)){
all_ind <- all_ind_complete[all_ind_complete$file==trimesters[i],]
myPalette <-  colorRampPalette(c("dodgerblue4", "dodgerblue1","deepskyblue","darkslategray1", "lightcyan",  "lemonchiffon1","khaki","sandybrown", "darkorange2","firebrick2"))
ind <- ggplot(sel, aes(x=long,y=lat)) +
geom_polygon(aes(group=group),fill="snow") +
geom_point(data=all_ind, aes(x= longitud, y= latitud, group= 1 ,col=kendall),size=3) +
geom_path(aes(long,lat,group=group),color="black",size=0.3)  +
theme_bw() + scale_color_gradientn(colours =myPalette(100), limits=c(0,100)) + coord_equal()+
labs(title="2AFC Score", x=" ", y=" ", col=" ")+theme( legend.position = "bottom",legend.key.width  = unit(1.5, "cm"))
ind_1 <- ggplot(sel, aes(x=long,y=lat)) +
geom_polygon(aes(fill=hole,group=group),fill="snow") +
geom_point(data=all_ind, aes(x= longitud, y= latitud, group= 1 ,col=pearson),size=3) +
geom_path(aes(long,lat,group=group),color="black",size=0.3)  +
theme_bw() + scale_color_gradientn(colours =myPalette(100), limits=c(-1,1)) + coord_equal() +
labs(title="Pearson's Correlation", x=" ", y=" ", col=" ")+ theme(legend.position = "bottom",legend.key.width  = unit(1.5, "cm"))
ind_2 <-ggplot(sel, aes(x=long,y=lat)) +
geom_polygon(aes(fill=hole,group=group),fill="snow") +
geom_point(data=all_ind, aes(x= longitud, y= latitud, group= 1 ,col=roc_b),size=3) +
geom_path(aes(long,lat,group=group),color="black",size=0.3)  +
theme_bw() + scale_color_gradientn(colours =myPalette(100), limits=c(0,1)) + coord_equal() +
labs(title="ROC Area (Below-Normal)", x=" ", y=" ", col=" ")+ theme(legend.position = "bottom",legend.key.width  = unit(1.5, "cm"))
ind_3 <-ggplot(sel, aes(x=long,y=lat)) +
geom_polygon(aes(fill=hole,group=group),fill="snow") +
geom_point(data=all_ind, aes(x= longitud, y= latitud, group= 1 ,col=roc_a),size=3) +
geom_path(aes(long,lat,group=group),color="black",size=0.3)  +
theme_bw() + scale_color_gradientn(colours =myPalette(100), limits=c(0,1)) + coord_equal() +
labs(title="ROC Area (Above-Normal)", x=" ", y=" ", col=" ")+ theme(legend.position = "bottom",legend.key.width  = unit(1.5, "cm"))
ind_4 <-ggplot(sel, aes(x=long,y=lat)) +
geom_polygon(aes(fill=hole,group=group),fill="snow") +
geom_point(data=all_ind, aes(x= longitud, y= latitud, group= 1 ,col=hit_s),size=3) +
geom_path(aes(long,lat,group=group),color="black",size=0.3)  +
theme_bw() + scale_color_gradientn(colours =myPalette(100), limits=c(0,100)) + coord_equal() +
labs(title="Hit Score", x=" ", y=" ", col=" ")+ theme(legend.position = "bottom",legend.key.width  = unit(1.5, "cm"))
ind_5 <-ggplot(sel, aes(x=long,y=lat)) +
geom_polygon(aes(fill=hole,group=group),fill="snow") +
geom_point(data=all_ind, aes(x= longitud, y= latitud, group= 1 ,col=hit_ss),size=3) +
geom_path(aes(long,lat,group=group),color="black",size=0.3)  +
theme_bw() + scale_color_gradientn(colours =myPalette(100), limits=c(-100,100)) + coord_equal() +
labs(title="Hit Skill Score", x=" ", y=" ", col=" ")+ theme(legend.position = "bottom",legend.key.width  = unit(1.5, "cm"))
layt<-grid.layout(nrow=2,ncol=1)
tiff(filename = paste0(path_output,"/" ,trimesters[i], "_metrics_maps.tif"), width = 800, height = 800,res=130,compression = 'lzw')
grid.newpage()
pushViewport(viewport(layout=layt))
print(ind,vp=viewport(layout.pos.row=1,layout.pos.col=1))
print(ind_1,vp=viewport(layout.pos.row=2,layout.pos.col=1))
dev.off()
cat(paste0(trimesters[i])," Mapas Metricas realizados...\n")
layt<-grid.layout(nrow=2,ncol=1)
tiff(filename = paste0(path_output,"/" ,trimesters[i], "_roc_maps.tif"), width = 800, height = 800,res=130,compression = 'lzw')
grid.newpage()
pushViewport(viewport(layout=layt))
print(ind_2,vp=viewport(layout.pos.row=1,layout.pos.col=1))
print(ind_3,vp=viewport(layout.pos.row=2,layout.pos.col=1))
dev.off()
cat(paste0(trimesters[i])," Mapas ROC realizados...\n")
layt<-grid.layout(nrow=2,ncol=1)
tiff(filename = paste0(path_output,"/" ,trimesters[i], "_hit_maps.tif"), width = 800, height = 800,res=130,compression = 'lzw')
grid.newpage()
pushViewport(viewport(layout=layt))
print(ind_4,vp=viewport(layout.pos.row=1,layout.pos.col=1))
print(ind_5,vp=viewport(layout.pos.row=2,layout.pos.col=1))
dev.off()
cat(paste0(trimesters[i])," Mapas Hit realizados...\n")
max_C<-apply(all_ind[,c("below","normal","above")], 1, max)
cat<-ifelse(all_ind[,"below"]==max_C, "Below", ifelse(all_ind[,"normal"]==max_C, "Normal", ifelse(all_ind[,"above"]==max_C, "Above",0)))
maximos<-cbind.data.frame(all_ind$id, all_ind$longitud, all_ind$latitud, max_C, cat)
# Aqui se ingresan los datos de las estaciones
maximos$cat = factor(maximos$cat, levels = c("Below", "Normal", "Above"))
p <- ggplot(sel, aes(x=long,y=lat)) +
geom_polygon(aes(fill=hole,group=group),fill="snow")
maxi <- p + geom_point(data=maximos, aes(x=all_ind$longitud, y=all_ind$latitud, colour=cat))+
geom_path(aes(long,lat,group=group),color="black",size=0.3) + scale_colour_manual(values = c("tomato2","lightgreen","steelblue3")) +
coord_equal() + theme( legend.key.height=unit(1,"cm"),legend.key.width=unit(0.5,"cm"),
legend.text=element_text(size=8),
panel.background=element_rect(fill="white",colour="black"),
axis.text=element_text(colour="black",size=10),
axis.title=element_text(colour="black",size=10,face="bold"),
#legend.position = "bottom",
legend.title=element_blank())  + labs(title="Probabilistic Forecast")+labs( x=" ", y=" ", size=" ")
tiff(paste0(path_output,"/" ,trimesters[i], "_probabilistic_maps.tif"),width = 3000, height = 3000, units = "px", res = 400,compression = 'lzw')
print(maxi)
dev.off()
cat(paste0(trimesters[i]), " Mapas Probabilistico realizados...\n")
myPalette2 = colorRampPalette(c("steelblue2" , "deepskyblue", "lightcyan","khaki","yellow", "orange1","darkorange3", "red", "firebrick4"))
above <-ggplot(sel, aes(x=long,y=lat)) +
geom_polygon(aes(fill=hole,group=group),fill="snow") +
geom_point(data=all_ind, aes(x= longitud, y= latitud, group= 1 ,col=above),size=3) +
geom_path(aes(long,lat,group=group),color="black",size=0.3)  +
theme_bw() + scale_color_gradientn(colours =myPalette2(10), limits=c(0,100)) + coord_equal() +
labs(title="Above", x=" ", y=" ", col=" ")+ theme(legend.position = "bottom",legend.key.width  = unit(1.5, "cm"))
normal <-ggplot(sel, aes(x=long,y=lat)) +
geom_polygon(aes(fill=hole,group=group),fill="snow") +
geom_point(data=all_ind, aes(x= longitud, y= latitud, group= 1 ,col=normal),size=3) +
geom_path(aes(long,lat,group=group),color="black",size=0.3)  +
theme_bw() + scale_color_gradientn(colours =myPalette2(10), limits=c(0,100)) + coord_equal() +
labs(title="Normal", x=" ", y=" ", col=" ")+ theme(legend.position = "bottom",legend.key.width  = unit(1.5, "cm"))
below <-ggplot(sel, aes(x=long,y=lat)) +
geom_polygon(aes(fill=hole,group=group),fill="snow") +
geom_point(data=all_ind, aes(x= longitud, y= latitud, group= 1 ,col=below),size=3) +
geom_path(aes(long,lat,group=group),color="black",size=0.3)  +
theme_bw() + scale_color_gradientn(colours =myPalette2(10), limits=c(0,100)) + coord_equal() +
labs(title="Below", x=" ", y=" ", col=" ")+ theme(legend.position = "bottom",legend.key.width  = unit(1.5, "cm"))
layt<-grid.layout(nrow=1,ncol=3)
tiff(filename = paste0(path_output,"/" ,trimesters[i], "_probabilities_maps.tif"), width = 1400, height = 800,res=130,compression = 'lzw')
grid.newpage()
pushViewport(viewport(layout=layt))
print(below,vp=viewport(layout.pos.row=1,layout.pos.col=1))
print(normal,vp=viewport(layout.pos.row=1,layout.pos.col=2))
print(above,vp=viewport(layout.pos.row=1,layout.pos.col=3))
dev.off()
cat(paste0(trimesters[i])," Mapas Probabilidades realizados...\n")
}
}
tsm_list <- lapply(path_x,function(x)lapply(x,function(x1)read.table(x1,sep="\t",dec=".",skip =2,fill=TRUE,na.strings =-999,stringsAsFactors=FALSE)))
time=lapply(tsm_list,function(x)lapply(x,function(x1) as.character(x1[1,])[-1]))
time_sel=lapply(time,function(x)lapply(x,function(x1)x1[x1!="NA"]))
tsm_raster <- lapply(tsm_list,function(x)lapply(x,data_raster))
cat("\n Datos cargados en formato raster")
suppressMessages(if(!require(rworldmap)){install.packages('rworldmap'); library(rworldmap)} else {library(rworldmap)})
suppressMessages(if(!require(raster)){install.packages('raster'); library(raster)} else {library(raster)})
suppressMessages(if(!require(ggplot2)){install.packages('ggplot2'); library(ggplot2)} else {library(ggplot2)})
suppressMessages(if(!require(rasterVis)){install.packages('rasterVis'); library(rasterVis)} else {library(rasterVis)})
suppressMessages(if(!require(sf)){install.packages('sf'); library(sf)} else {library(sf)})
suppressMessages(if(!require(grid)){install.packages('grid'); library(grid)} else {library(grid)})
suppressMessages(if(!require(dplyr)){install.packages('dplyr'); library(dplyr)} else {library(dplyr)})
suppressMessages(if(!require(tidyr)){install.packages('tidyr'); library(tidyr)} else {library(tidyr)})
suppressMessages(if(!require(rgeos)){install.packages('rgeos'); library(rgeos)} else {library(rgeos)})
suppressMessages(if(require(stringr)==FALSE){install.packages("stringr",dependencies = TRUE)}) ;library("stringr")
suppressMessages(if(require(corpcor)==FALSE){install.packages("corpcor")}); library("corpcor")
suppressMessages(if(require(pcaPP)==FALSE){install.packages("pcaPP")}); library("pcaPP")
suppressMessages(if(require(RColorBrewer)==FALSE){install.packages("RColorBrewer")});library("RColorBrewer")
suppressMessages(if(require(parallel)==FALSE){install.packages("parallel")});library("parallel")
path_cc <- lapply(paste0(folders,"/output/raw_output"),function(x)list.files(x,full.names = T,pattern = "cca_cc"))
path_load <- lapply(paste0(folders,"/output/raw_output"),function(x)list.files(x,full.names = T,pattern = "cca_load_x"))
cc <-  lapply(path_cc,function(x)lapply(x,function(x1)read.table(x1,sep="\t",dec=".",header = T,row.names = 1,skip =2,fill=TRUE,na.strings =-999,stringsAsFactors=FALSE)))
load <- lapply(path_load,function(x)lapply(x,function(x1)read.table(x1,sep="\t",dec=".",skip =2,fill=TRUE,na.strings =-999,stringsAsFactors=FALSE)))
cor_tsm <- Map(function(x,y)Map(correl,x,y),cc,load)
cat("\n Correlación calculada")
names_selec <-Map(function(x,y) paste0(x,"/input/sst_cfsv2/",substr(y,1,nchar(y))) ,folders,names_x)
clusterExport(cl,list("files_x","tsm_raster","cor_tsm","names_selec","time_sel"),envir=environment())
clusterEvalQ(cl, library("sp"))
clusterEvalQ(cl, library("raster"))
o_empty_1=clusterMap(cl,function(x,y,z,r)Map(files_x,x,y,z,r),tsm_raster,cor_tsm,names_selec,time_sel)
cat("\n Archivos de la TSM construidos por deciles para CPT \n")
library(raster)
mapa = ("C:/Users/cbarrios/Downloads/dtr_MON_climextrem.ethiopia_historical_NA_1985-2015.nc")
mapa = stack("C:/Users/cbarrios/Downloads/dtr_MON_climextrem.ethiopia_historical_NA_1985-2015.nc")
mapa
nlayers(mapa)
names(mapa)
nlayers(mapa)
mapa[[1]]
plot(mapa[[1]])
dtr_Mon = stack("C:/Users/cbarrios/Downloads/dtr_MON_climextrem.ethiopia_historical_NA_1985-2015.nc")
dtr_Ann = stack("C:/Users/cbarrios/Downloads/dtr_ANN_climextrem.ethiopia_historical_NA_1985-2015")
dtr_Ann = stack("C:/Users/cbarrios/Downloads/dtr_ANN_climextrem.ethiopia_historical_NA_1985-2015.nc")
dtr_Ann
names(dtr_Ann)
plot(dtr_Ann[[1:5]])
names(mapa)
nlayers(dtr_Mon)
nlayers(dtr_Ann)
dtr_Ann
nlayers(dtr_Mon)
names(dtr_Mon)
plot(mapa[[1]])
plot(dtr_Mon[[1]])
nlayers(dtr_Ann)
names(dtr_Ann)
plot(dtr_Ann[[1:5]])
dtr_Mon
## Montlhy ##
dtr_Mon = stack("C:/Users/cbarrios/Downloads/dtr_MON_climextrem.ethiopia_historical_NA_1985-2015.nc")
nlayers(dtr_Mon)
names(dtr_Mon)
plot(dtr_Mon[[1]])
plot(dtr_Mon[[1:3]])
dtr_Mon[[1]]
writeRaster(dtr_Mon[[1]], "D:/OneDrive - CGIAR/Desktop/Ejemplo_Exportar/dtr_198501.tif")
###########################
path = "https://maps.isric.org/mapserv?map=/map/clay.map&SERVICE=WCS&VERSION=2.0.1&REQUEST=GetCoverage&COVERAGEID=clay_0-5cm_mean&FORMAT=image/tiff&SUBSET=long(-74.0000,-72.0000)&SUBSET=lat(3.5000,5.5000)&SUBSETTINGCRS=http://www.opengis.net/def/crs/EPSG/0/4326&OUTPUTCRS=http://www.opengis.net/def/crs/EPSG/0/4326"
browseURL(path, browser = getOption("browser"),encodeIfNeeded = FALSE)
library(raster)
library(rgdal)
library(fields)
library(rasterVis)
library(maps)
library(maptools)
library(rgeos)
###############################
## Set the working directory ##
###############################
setwd("D:/OneDrive - CGIAR/CAF-IDEAM Project/Capitulo 3/Analisis_IDH_Maiz_Arroz/Base de datos/Variables de suelo por region/Llanos")
############################################
## Import soil information from SoilGrids ##
############################################
##################
## Clay content ##
##################
Clay = list.files(path = paste(getwd(),"/","Clay content",sep =""), pattern="tif$", full.names = TRUE, recursive = FALSE)
Clay_2 = Clay
Clay[1] = Clay_2 [1]
Clay[2] = Clay_2 [4]
Clay[3] = Clay_2 [2]
Clay[4] = Clay_2 [3]
Clay_rasters = lapply(Clay, raster)
Clay_rasters = stack(Clay_rasters)
## Units convertion ##
Clay_final = (Clay_rasters/10) # This converts Clay content units from g/kg to %
##################
## Sand content ##
##################
Sand = list.files(path = paste(getwd(),"/","Sand content",sep =""), pattern="tif$", full.names = TRUE, recursive = FALSE)
Sand_2 = Sand
Sand[1] = Sand_2 [1]
Sand[2] = Sand_2 [4]
Sand[3] = Sand_2 [2]
Sand[4] = Sand_2 [3]
Sand_rasters = lapply(Sand, raster)
Sand_rasters = stack(Sand_rasters)
## Units convertion ##
Sand_final = (Sand_rasters/10) # This converts Sand content units from g/kg to %
##################
## Bulk density ##
##################
BLD = list.files(path = paste(getwd(),"/","Bulk density",sep =""), pattern="tif$", full.names = TRUE, recursive = FALSE)
BLD_2 = BLD
BLD[1] = BLD_2 [1]
BLD[2] = BLD_2 [4]
BLD[3] = BLD_2 [2]
BLD[4] = BLD_2 [3]
BLD_rasters = lapply(BLD, raster)
BLD_rasters = stack(BLD_rasters)
## Units convertion ##
BLD_final = (BLD_rasters/100) # This converts BLD units from cg/cm3 to Mg/m3
########
## pH ##
########
pH = list.files(path = paste(getwd(),"/","pH",sep =""), pattern="tif$", full.names = TRUE, recursive = FALSE)
pH_2 = pH
pH[1] = pH_2 [1]
pH[2] = pH_2 [4]
pH[3] = pH_2 [2]
pH[4] = pH_2 [3]
pH_rasters = lapply(pH, raster)
pH_rasters = stack(pH_rasters)
## Units convertion ##
pH_final = (pH_rasters/10) # This converts pH units
#############################
## Cation Echange Capacity ##
#############################
CEC = list.files(path = paste(getwd(),"/","CEC",sep =""), pattern="tif$", full.names = TRUE, recursive = FALSE)
CEC_2 = CEC
CEC[1] = CEC_2 [1]
CEC[2] = CEC_2 [4]
CEC[3] = CEC_2 [2]
CEC[4] = CEC_2 [3]
CEC_rasters = lapply(CEC, raster)
CEC_rasters = stack(CEC_rasters) # Units in cmol/kg
## Units convertion ##
CEC_final = (CEC_rasters/10) # This converts CEC units from mmol(c)/cm3 to cmol/kg
#####################################################################################
## Computation of saturated soil water content (SSWC) (m3 m-3) per each soil layer ##
#####################################################################################
###########################
## SSWC for 0-5 cm depth ##
###########################
SSWC_0_5cm = 0.81799 + ((9.9*10^-4)*Clay_final[[1]]) - (0.3142*BLD_final[[1]]) + ((1.8*10^-4)*CEC_final[[1]]) + (0.00451*pH_final[[1]]) - ((5*10^-6)*(Sand_final[[1]])*(Clay_final[[1]]))
###########################
## SSWC for 5-15 cm depth ##
###########################
SSWC_5_15cm = 0.81799 + ((9.9*10^-4)*Clay_final[[2]]) - (0.3142*BLD_final[[2]]) + ((1.8*10^-4)*CEC_final[[2]]) + (0.00451*pH_final[[2]]) - ((5*10^-6)*(Sand_final[[2]])*(Clay_final[[2]]))
#############################
## SSWC for 15-30 cm depth ##
#############################
SSWC_15_30cm = 0.81799 + ((9.9*10^-4)*Clay_final[[3]]) - (0.3142*BLD_final[[3]]) + ((1.8*10^-4)*CEC_final[[3]]) + (0.00451*pH_final[[3]]) - ((5*10^-6)*(Sand_final[[3]])*(Clay_final[[3]]))
#############################
## SSWC for 30-60 cm depth ##
#############################
SSWC_30_60cm = 0.81799 + ((9.9*10^-4)*Clay_final[[4]]) - (0.3142*BLD_final[[4]]) + ((1.8*10^-4)*CEC_final[[4]]) + (0.00451*pH_final[[4]]) - ((5*10^-6)*(Sand_final[[4]])*(Clay_final[[4]]))
################################################################
## Conversion of saturated soil moisture data (m3/m3) into mm ##
################################################################
######################################
## SSWC in mm for 0-5 cm soil depth ##
######################################
SSWC_mm_0_5cm = SSWC_0_5cm*50 # 50 is the depth of the first soil layer (5 cm) in mm
#######################################
## SSWC in mm for 5-15 cm soil depth ##
#######################################
SSWC_mm_5_15cm = SSWC_5_15cm*100 # 100 is the depth of the second soil layer (10 cm) in mm
########################################
## SSWC in mm for 15-30 cm soil depth ##
########################################
SSWC_mm_15_30cm = SSWC_15_30cm*150 # 150 is the depth of the third soil layer (15 cm) in mm
########################################
## SSWC in mm for 30-60 cm soil depth ##
########################################
SSWC_mm_30_60cm = SSWC_30_60cm*300 # 300 is the depth of the fourth soil layer (30 cm) in mm
plot(SSWC_mm_30_60cm)
#########################################
## Maximum soil water holding capacity ##
#########################################
Max_SWHC = SSWC_mm_0_5cm + SSWC_mm_5_15cm + SSWC_mm_15_30cm + SSWC_mm_30_60cm
plot(Max_SWHC)
Max_SWHC
Stations_Meta = read.table ("D:/OneDrive - CGIAR/CAF-IDEAM Project/Capítulo 2/Daily climate information/Llanos/Coordenadas_Estaciones_Meta_Casanare.csv")
View(Stations_Meta)
Stations_Meta = read.table ("D:/OneDrive - CGIAR/CAF-IDEAM Project/Capítulo 2/Daily climate information/Llanos/Coordenadas_Estaciones_Meta_Casanare.csv", sep=",")
View(Stations_Meta)
Stations_Meta = read.table ("D:/OneDrive - CGIAR/CAF-IDEAM Project/Capítulo 2/Daily climate information/Llanos/Coordenadas_Estaciones_Meta_Casanare.csv", head=T, sep=",")
coordinates = c(Stations_Meta$Lon, Stations_Meta$Lat)
coordinates
coordinates = cbind(Stations_Meta$Lon, Stations_Meta$Lat)
coordinates
names(coordinates)[1:2] = c("x", "y")
View(coordinates)
coordinates
coordinates = cbind(Stations_Meta$Lon, Stations_Meta$Lat)
coordinates
coordinates = as.data.frame(cbind(Stations_Meta$Lon, Stations_Meta$Lat))
names(coordinates)[1:2] = c("x", "y")
coordinates
points(coordinates, add=T)
data_Max_SWHC = extract(Max_SWHC, coordinates)
data_Max_SWHC
data_Max_SWHC = as.data.frame(extract(Max_SWHC, coordinates))
data_Max_SWHC
names(data_Max_SWHC)[1] = c("Max_SWHC")
data_Max_SWHC
data_Max_SWHC = cbind(Stations_Meta, data_Max_SWHC)
data_Max_SWHC
coordinates
options(timeout=360)
if(require(stringr)==FALSE){install.packages("stringr",dependencies = TRUE)}
library("stringr")
if(require(R.utils)==FALSE){install.packages("R.utils",dependencies = TRUE)}
library(R.utils)
suppressMessages(if(require(parallel)==FALSE){install.packages("parallel")});library("parallel")
####### function ######
download_ERSST_CPT=function(firs_year,last_year,i_month,l_season,dir_save,m_for,l_for,area1){
trimestrel <- i_month:(i_month+l_season-1)
fores <- m_for:(m_for+l_for-1)
if(sum(fores>12)>0)fores[which(fores>12)]=fores[which(fores>12)]-12
if(sum(trimestrel>12)>0)trimestrel[which(trimestrel>12)]=trimestrel[which(trimestrel>12)]-12
route <- paste0("http://iridl.ldeo.columbia.edu/SOURCES/.NOAA/.NCDC/.ERSST/.version4/.sst/T/%28", month.abb[trimestrel[1]] ,"%20", firs_year ,"%29%28",  month.abb[trimestrel[l_season]] ,"%20", last_year ,"%29RANGEEDGES/T/", l_season ,"/boxAverage/T/12/STEP/Y/%28",area1[4],"%29%28",area1[3],"%29RANGEEDGES/X/%28",area1[1],"%29%28",area1[2],"%29RANGEEDGES/-999/setmissing_value/Y/high/low/RANGE/%5BX/Y%5D%5BT%5Dcptv10.tsv.gz")
path_save <- paste0(dir_save,"/",paste(month.abb[fores],collapse = "-"),"_",paste(month.abb[trimestrel],collapse = "-"),".tsv.gz")
#download.file(route,path_save)
#gunzip(path_save)
status = 1
while(status!=200){
res1 <- httr::GET(route,httr::write_disk(path_save, overwrite=TRUE), config = httr::config(connecttimeout = 60))
status = res1$status_code
print(status)
}
return(paste("Successful download",path_save))
}
main_dir <- "D:/OneDrive - CGIAR/Desktop/Ejemplo_Dowload_ERSST/" # Modifique esta línea de acuerdo a su directorio de trabajo
lapply(paste0(main_dir, 2012:2022,"/input/sst_ersst"),function(x)dir.create(x,recursive = T))
lapply(paste0(main_dir, 2012:2022,"/input/stations"),function(x)dir.create(x,recursive = T))
main_dir <- "D:/OneDrive - CGIAR/Desktop/Ejemplo_Dowload_ERSST/" # Modifique esta línea de acuerdo a su directorio de trabajo
lapply(paste0(main_dir, 2012:2022,"/input/sst_ersst"),function(x)dir.create(x,recursive = T))
lapply(paste0(main_dir, 2012:2022,"/input/stations"),function(x)dir.create(x,recursive = T))
area1 <- list(c(0,360,-20,40))#xmin, xmax, ymin, ymax
i_month <-  c(5,6,7,8,11,  4,5,6,7,10,  1,2,3,4,7) #First month to download
l_season <- c(3,3,2,3,3 ,  1,1,1,1,1 ,  1,1,1,1,1) #Length season (1, 2, 3. meses)
m_for <-    c(5,6,7,8,11,  5,6,7,8,11,  5,6,7,8,11) #Month to forecast
l_for <-    c(3,3,2,3,3 ,  3,3,2,3,3 ,  3,3,2,3,3) #Length forescast
firs_year <- 1981 #Initial year
numCores <- detectCores()
numCores
cl <- makeCluster(numCores-3)
clusterExport(cl,list("area1","i_month","l_season","m_for","l_for","firs_year","download_ERSST_CPT"),envir=environment())
clusterEvalQ(cl, c(library("R.utils"),library("httr")) )
for(i in 2012:2022){
last_year <- i #Last year
dir_save <- paste0(main_dir,i,"/input/sst_ersst")
clusterExport(cl,list("last_year","dir_save"),envir=environment())
clusterMap(cl,download_ERSST_CPT,firs_year,last_year,i_month,l_season,dir_save,m_for,l_for,area1)
}
stopCluster(cl)
all_path_down=list.files( "D:/OneDrive - CGIAR/Desktop/Ejemplo_Dowload_ERSST/",full.names = T,recursive = TRUE)
gz_o=lapply(all_path_down,function(x)lapply(x,function(x1)gunzip(x1)))
